{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c329ad59-a6af-4515-ae66-d8fee0d61ac1",
   "metadata": {},
   "source": [
    "# Chapter 7 - Open-source Frameworks: Contextual Text and Image Search Engine with Amazon Bedrock\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to build a multimodal search engine that can handle both text and images using Amazon Bedrock. We'll explore how to create embeddings for different content types and perform semantic search across multimedia content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d339df-02b4-4b5b-b95f-3b103e82fa9b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to build a product recommendation search engine that understands both text and images using Amazon Bedrock's Titan Multimodal Embedding model and FAISS vector database. The system enables powerful semantic search across product data, allowing users to find visually and contextually similar products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c00d967-b6bd-491f-8f86-fad025a541fc",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- AWS account with Amazon Bedrock access\n",
    "- Access to Titan Multimodal Embedding model \n",
    "- The Amazon Berkeley Objects dataset (sample product catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8930b-eafd-4c1b-ac49-0131332e071c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:07:20.611553Z",
     "iopub.status.busy": "2025-07-08T17:07:20.611179Z",
     "iopub.status.idle": "2025-07-08T17:07:20.615693Z",
     "shell.execute_reply": "2025-07-08T17:07:20.614666Z",
     "shell.execute_reply.started": "2025-07-08T17:07:20.611524Z"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8887b5a-dea8-4536-a343-647054197d2a",
   "metadata": {},
   "source": [
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732613a-d885-4049-ba27-b9b7553ad01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opensearch-py\n",
    "!pip install requests-aws4auth\n",
    "!pip install -U boto3\n",
    "!pip install -U botocore\n",
    "!pip install -U awscli\n",
    "!pip install s3fs\n",
    "!pip install sns\n",
    "!pip install seaborn\n",
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735dfcd-2a30-4648-a13e-05c7a29fa300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U --no-cache-dir boto3\n",
    "%pip install -U --no-cache-dir  \\\n",
    "    \"langchain>=0.1.11\" \\\n",
    "    sqlalchemy -U \\\n",
    "    \"faiss-cpu>=1.7,<2\" \\\n",
    "    \"pypdf>=3.8,<4\" \\\n",
    "    pinecone-client==2.2.4 \\\n",
    "    apache-beam==2.52. \\\n",
    "    tiktoken==0.5.2 \\\n",
    "    \"ipywidgets>=7,<8\" \\\n",
    "    matplotlib==3.8.2 \\\n",
    "    anthropic==0.9.0\n",
    "%pip install -U --no-cache-dir transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09010dde-569f-453d-aac1-bee33275b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94fb564-7269-48ec-b472-6c59eaca6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef9829-2456-428b-a5cf-791a64f88ef9",
   "metadata": {},
   "source": [
    "### Initialize AWS Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adadf967-a27f-4136-a0bb-03ea23b70518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sagemaker.s3 import S3Downloader as s3down\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8bd54-56b4-4fea-9388-5ad6173d5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from IPython.display import Markdown, display, Pretty\n",
    "\n",
    "# getting boto3 clients for required AWS services\n",
    "sts_client = boto3.client('sts')\n",
    "s3_client = boto3.client('s3')\n",
    "#aoss_client = boto3.client('opensearchserverless')\n",
    "\n",
    "\n",
    "# Configure AWS clients\n",
    "region = os.environ.get(\"AWS_REGION\")\n",
    "boto3_bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de71643-e34f-4997-a67d-cb7fb824579c",
   "metadata": {},
   "source": [
    "### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d784620-7fc6-4fad-a106-f3029aa07751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bedrock models\n",
    "# Select Amazon titan-embed-image-v1 as Embedding model for multimodal indexing\n",
    "multimodal_embed_model = f'amazon.titan-embed-image-v1'\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Function to plot heatmap from embeddings\n",
    "\"\"\"\n",
    "\n",
    "def plot_similarity_heatmap(embeddings_a, embeddings_b):\n",
    "    inner_product = np.inner(embeddings_a, embeddings_b)\n",
    "    sns.set(font_scale=1.1)\n",
    "    graph = sns.heatmap(\n",
    "        inner_product,\n",
    "        vmin=np.min(inner_product),\n",
    "        vmax=1,\n",
    "        cmap=\"OrRd\",\n",
    "    )\n",
    "\n",
    "\"\"\" \n",
    "Function to fetch the image based on image id from dataset\n",
    "\"\"\"\n",
    "def get_image_from_item_id( item_id = \"0\", dataset = None, return_image=True):\n",
    " \n",
    "    item_idx = dataset.query(f\"item_id == {item_id}\").index[0]\n",
    "    img_path = dataset.iloc[item_idx].image_path\n",
    "    \n",
    "    if return_image:\n",
    "        img = Image.open(img_path)\n",
    "        return img, dataset.iloc[item_idx].item_desc\n",
    "    else:\n",
    "        return img_path, dataset.iloc[item_idx].item_desc\n",
    "    print(item_idx,img_path)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Function to fetch the image based on image id from S3 bucket\n",
    "\"\"\"\n",
    "    \n",
    "def get_image_from_item_id_s3(item_id = \"B0896LJNLH\", dataset = None, image_path = None,  return_image=True):\n",
    "\n",
    "    item_idx = dataset.query(f\"item_id == '{item_id}'\").index[0]\n",
    "    img_loc =  dataset.iloc[item_idx].img_full_path\n",
    "    \n",
    "    if img_loc.startswith('s3'):\n",
    "        # download and store images locally \n",
    "        local_data_root = f'./data/images'\n",
    "        local_file_name = img_loc.split('/')[-1]\n",
    " \n",
    "        s3down.download(img_loc, local_data_root)\n",
    " \n",
    "    local_image_path = f\"{local_data_root}/{local_file_name}\"\n",
    "    \n",
    "    if return_image:\n",
    "        img = Image.open(local_image_path)\n",
    "        return img, dataset.iloc[item_idx].item_name_in_en_us\n",
    "    else:\n",
    "        return local_image_path, dataset.iloc[item_idx].item_name_in_en_us\n",
    "\n",
    "\"\"\" \n",
    "Function to display the images.\n",
    "\"\"\"\n",
    "def display_images(images: [Image], columns=2, width=20, height=8, max_images=15, label_wrap_length=50, label_font_size=8):\n",
    " \n",
    "    if not images:\n",
    "        print(\"No images to display.\")\n",
    "        return \n",
    " \n",
    "    if len(images) > max_images:\n",
    "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
    "        images=images[0:max_images]\n",
    " \n",
    "    height = max(height, int(len(images)/columns) * height)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    " \n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.imshow(image)\n",
    " \n",
    "        if hasattr(image, 'name_and_score'):\n",
    "            plt.title(image.name_and_score, fontsize=label_font_size); \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25143cc5-6e65-40d4-a000-fd6ae24f2ca2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dabc97-6b0b-4786-8022-a6485963e375",
   "metadata": {},
   "source": [
    "### Load Product Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e60aa-55d1-4deb-8f66-8e39090c0a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16338165-bb0d-4202-9e52-d39abb888d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product metadata\n",
    "meta = pd.read_json(\"s3://amazon-berkeley-objects/listings/metadata/listings_0.json.gz\", lines=True)\n",
    "# Extract English product titles\n",
    "def func_(x):\n",
    "    us_texts = [item[\"value\"] for item in x if item[\"language_tag\"] == \"en_US\"]\n",
    "    return us_texts[0] if us_texts else None\n",
    "\n",
    "meta = meta.assign(item_name_in_en_us=meta.item_name.apply(func_))\n",
    "meta = meta[~meta.item_name_in_en_us.isna()][[\"item_id\", \"item_name_in_en_us\", \"main_image_id\"]]\n",
    "print(f\"#products with US English title: {len(meta)}\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9b241-cc71-41e1-a4a8-bc358c187844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image metadata and merge with product data\n",
    "image_meta = pd.read_csv(\"s3://amazon-berkeley-objects/images/metadata/images.csv.gz\")\n",
    "dataset = meta.merge(image_meta, left_on=\"main_image_id\", right_on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b8472-3260-482c-8f7f-387507184a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in dataset with FULL PATH of the image\n",
    "dataset = dataset.assign(img_full_path=f's3://amazon-berkeley-objects/images/small/' + dataset.path.astype(str))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704741b-3646-489e-9c7f-78ef06a8093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, item_name = get_image_from_item_id_s3(item_id = \"B07JQX8S2X\", dataset = dataset, image_path = f's3://amazon-berkeley-objects/images/small/' )\n",
    "print(item_name)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf79638-b3a0-44e9-8c68-49aac12d454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a small batch for demonstration\n",
    "batch_size=10\n",
    "dataset = dataset.iloc[:batch_size]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c31290-e033-48aa-a229-eef5528c39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_details in enumerate(zip(dataset['img_full_path'], dataset['item_name_in_en_us'])):\n",
    "    print(img_details[0], img_details[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd4768-9a66-4717-a29c-b1b542b3e79f",
   "metadata": {},
   "source": [
    "## Generate Multimodal Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5d61d-540f-48ad-abcf-d6c963d74901",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def get_titan_multimodal_embedding_fix(\n",
    "    image_path:str=None,  # maximum 2048 x 2048 pixels\n",
    "    description:str=None, # English only and max input tokens 128\n",
    "    dimension:int=1024,   # 1,024 (default), 384, 256\n",
    "    model_id:str=multimodal_embed_model\n",
    "):\n",
    "    # print(image_path)\n",
    "    # print(description)\n",
    "    payload_body = {}\n",
    "    embedding_config = {\n",
    "        \"embeddingConfig\": { \n",
    "             \"outputEmbeddingLength\": dimension\n",
    "         }\n",
    "    }\n",
    "    # You can specify either text or image or both\n",
    "    if image_path:\n",
    "        if image_path.startswith('s3'):\n",
    "            s3 = boto3.client('s3')\n",
    "            bucket_name, key = image_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "            obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "            # Read the object's body\n",
    "            body = obj['Body'].read()\n",
    "            # Encode the body in base64\n",
    "            base64_image = base64.b64encode(body).decode('utf-8')\n",
    "            payload_body[\"inputImage\"] = base64_image\n",
    "        else:   \n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                input_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "            payload_body[\"inputImage\"] = input_image\n",
    "    if description:\n",
    "        payload_body[\"inputText\"] = description\n",
    "\n",
    "    # print(payload_body)\n",
    "    # print(json.dumps({**payload_body, **embedding_config}))\n",
    "    print(f\" get_titan_multimodal_embedding_fix()::payload:keys={payload_body.keys()}::\")\n",
    "    response = boto3_bedrock.invoke_model(\n",
    "        body=json.dumps({**payload_body, **embedding_config}), \n",
    "        modelId=model_id,\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    return json.loads(response.get(\"body\").read())\n",
    "\n",
    "# Generate embeddings for each product\n",
    "multimodal_embeddings_img = []\n",
    "for img_details in enumerate(zip(dataset['img_full_path'], dataset['item_name_in_en_us'])):\n",
    "    #print(img_details[1])\n",
    "    embedding = get_titan_multimodal_embedding_fix(description=img_details[1][1], image_path=img_details[1][0], dimension=1024)[\"embedding\"]\n",
    "    print(np.array(embedding).shape)\n",
    "    multimodal_embeddings_img.append(embedding)\n",
    "\n",
    "# Add embeddings to dataset\n",
    "dataset = dataset.assign(embedding_img=multimodal_embeddings_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5a30c-0dfe-4fff-b40f-913efe2063a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af57e80-55df-492b-8eaf-b0aa244fb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['item_name_in_en_us'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ed184-6f2b-416a-936c-95164728174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_similarity_heatmap(multimodal_embeddings_img[:batch_size], multimodal_embeddings_img[:batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddfd6f-498f-4e40-ab19-32d7feca06ed",
   "metadata": {},
   "source": [
    "## Create Vector Store with FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9b401-abcb-48c1-9afd-985091e6744c",
   "metadata": {},
   "source": [
    "### Prepare Metadata for Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb5811-2c34-4fc2-8a66-2fc09a83c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83219757-60a5-4858-869b-309c0161a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare metadata dictionaries\n",
    "metadata_dict =  [ {key:value} for i, (key, value) in enumerate(zip(dataset['item_name_in_en_us'].to_list(), dataset['img_full_path'].to_list()))] \n",
    "metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc2a90-5852-41e5-bf4f-2f08a8e3fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector store\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Import from langchain_aws instead of langchain.embeddings\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "multimodal_embed_model = 'amazon.titan-embed-image-v1'\n",
    "# create instantiation to embedding model\n",
    "embedding_model = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=multimodal_embed_model\n",
    ")\n",
    "\n",
    "text_embedding_pairs = zip(dataset['item_name_in_en_us'].to_list(), multimodal_embeddings_img)\n",
    "\n",
    "# It seems metadata_dict is commented out, but you're using it in the FAISS creation\n",
    "# Make sure to define metadata_dict before using it\n",
    "metadata_dict = [{\"item_name\": name, \"img_path\": path} for name, path in zip(dataset['item_name_in_en_us'].to_list(), dataset['img_full_path'].to_list())]\n",
    "\n",
    "db = FAISS.from_embeddings(text_embedding_pairs, embedding_model, metadatas=metadata_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c716f70-6c1d-44ab-bbcd-58b99c79f69a",
   "metadata": {},
   "source": [
    "## Perform Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b75c83-1815-4467-a828-a191244fda4a",
   "metadata": {},
   "source": [
    "### Test Search Functionality with Text Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb72bc-cb5e-4a03-9777-5dab87092802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text query\n",
    "query_prompt = \"drinkware glass\"\n",
    "\n",
    "v = embedding_model.embed_query(query_prompt)\n",
    "print(v[0:10])\n",
    "results = db.similarity_search_by_vector(v, k=2)\n",
    "display(Markdown('Let us look at the documents which had the relevant information pertaining to our query'))\n",
    "for r in results:\n",
    "    display(Markdown(f'{r.page_content}'), Markdown(f'{r.metadata}'))\n",
    "    display(Markdown(f'------------------------------------'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d9d63-9e84-4e2a-a04a-6989dbff09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0].metadata.values())\n",
    "print(results[0].metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610aa68-7d6d-4d9c-973a-90192e1fa80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_from_faiss_results(results=None):\n",
    "    image_list = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Extract only the image path from metadata\n",
    "        img_path = result.metadata['img_path']\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        \n",
    "        if img_path.startswith('s3'):\n",
    "            # download and store images locally \n",
    "            local_data_root = f'./data/images'\n",
    "            local_file_name = img_path.split('/')[-1]\n",
    "            \n",
    "            # Make sure the directory exists\n",
    "            import os\n",
    "            os.makedirs(local_data_root, exist_ok=True)\n",
    "            \n",
    "            # Download the image\n",
    "            s3down.download(img_path, local_data_root)\n",
    "            \n",
    "            local_image_path = f\"{local_data_root}/{local_file_name}\"\n",
    "            \n",
    "            # Check if file exists before opening\n",
    "            if os.path.exists(local_image_path):\n",
    "                img = Image.open(local_image_path)\n",
    "                image_list.append(img)\n",
    "            else:\n",
    "                print(f\"Warning: Could not find downloaded image at {local_image_path}\")\n",
    "        else:\n",
    "            print(f\"Skipping non-S3 path: {img_path}\")\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55962a0a-43c2-47f9-bca5-1aa0bf592c59",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1. Perform Image Search based on Text Input\n",
    "\n",
    "Let’s take a look at the results of a simple query. In below example, we'll receive an text input i.e. \"drinkware glass\" from user, and then will send it to search engine to find the similar items.\n",
    "\n",
    "Find the similar items based on use queries. You can see that we found glass drinkware from our dataset based on the input query. That's what we want to achieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a9c61-06b7-4ed7-8585-62cdfc56eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = \"drinkware glass\"\n",
    "v = embedding_model.embed_query(query_prompt)\n",
    "results = db.similarity_search_by_vector(v, k=2)\n",
    "\n",
    "all_images = get_image_from_faiss_results(results)\n",
    "\n",
    "# If the display_images function exists, use it\n",
    "if all_images:\n",
    "    display_images(all_images)\n",
    "else:\n",
    "    print(\"No images were retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45200f91-7db9-42ff-af84-c90d138e385d",
   "metadata": {},
   "source": [
    "### Retrieve and Display Images from Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80959ac5-95d3-4531-af75-cff2d68afbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0896LJNLH\"\n",
    "\n",
    "image, item_name = get_image_from_item_id_s3(item_id = item_id, dataset = dataset, image_path = f's3://amazon-berkeley-objects/images/small/' )\n",
    "print(item_name)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d4481-82c7-4d34-96a6-a097b7437449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Function for semantic search capability using knn on input image prompt.\n",
    "\"\"\"\n",
    "def find_similar_items_from_image(image_path: str, k_nn: int ) -> []:\n",
    "    \"\"\"\n",
    "    Main semantic search capability using knn on input image prompt.\n",
    "    Args:\n",
    "        k: number of top-k similar vectors to retrieve from OpenSearch index\n",
    "        num_results: number of the top-k similar vectors to retrieve\n",
    "        index_name: index name in OpenSearch\n",
    "    \"\"\"\n",
    "    query_emb = get_titan_multimodal_embedding_fix(image_path=search_image_path, dimension=1024)[\"embedding\"]\n",
    "    #print(query_emb)\n",
    "    results = db.similarity_search_by_vector(query_emb, k=2)\n",
    "    print(results)\n",
    "    image_list = get_image_from_faiss_results(results)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41650cc5-c770-4d87-be44-d2d778e95634",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0896LJNLH\"\n",
    "search_image_path = dataset[dataset['item_id']==item_id]['img_full_path'].iloc[0]\n",
    "print(search_image_path)\n",
    "\n",
    "image_list = find_similar_items_from_image(search_image_path, 2)\n",
    "display_images(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda1465-253d-4218-b118-e1457c9c717c",
   "metadata": {},
   "source": [
    "\n",
    "### Retrieve and Display Images from Search Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7014e-cea0-4f6b-b45c-fd238ac48a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import boto3\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Setup S3 client for downloading the image\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 path and extract bucket and key\n",
    "s3_path = \"s3://amazon-berkeley-objects/images/small/07/075e5d67.jpg\"\n",
    "bucket_name = s3_path.split('/')[2]\n",
    "object_key = '/'.join(s3_path.split('/')[3:])\n",
    "\n",
    "# Create local directory for the image if it doesn't exist\n",
    "local_data_root = './data/images'\n",
    "os.makedirs(local_data_root, exist_ok=True)\n",
    "\n",
    "# Define the local path for the downloaded image\n",
    "local_file_name = s3_path.split('/')[-1]\n",
    "local_image_path = f\"{local_data_root}/{local_file_name}\"\n",
    "\n",
    "# Download the image from S3\n",
    "try:\n",
    "    s3.download_file(bucket_name, object_key, local_image_path)\n",
    "    print(f\"Successfully downloaded image to {local_image_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading image: {e}\")\n",
    "    # Use a fallback image path if download fails\n",
    "    local_image_path = \"data/images/departure_rate.jpg\"\n",
    "\n",
    "# Setup Bedrock client\n",
    "region = os.environ.get(\"AWS_REGION\")\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region,\n",
    ")\n",
    "\n",
    "# Read and encode the image\n",
    "with open(local_image_path, \"rb\") as image_file:\n",
    "    content_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "# Display the image we're about to send\n",
    "img = Image.open(local_image_path)\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a7219-3264-42be-8597-6285c4d4c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the request body\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 300,\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/jpeg\",\n",
    "                    \"data\": content_image,\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Describe this product in detail. What is it used for? What are its key features?\"\n",
    "            }\n",
    "            ]\n",
    "        }],\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.9\n",
    "    }  \n",
    ")  \n",
    "\n",
    "# Define model and invoke it\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    \n",
    "    # Display the response\n",
    "    print(\"\\nClaude's description:\")\n",
    "    print(response_body['content'][0]['text'])\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5de042-ca1f-479f-b84c-49db62e30757",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to build a contextual text and image search engine using Amazon Bedrock's Titan Multimodal Embedding model and FAISS vector database. The system enables powerful semantic search capabilities that understand both visual and textual context, making it ideal for product recommendation systems.\n",
    "\n",
    "The approach can be extended to larger datasets and more complex search requirements by:\n",
    "- Scaling the vector database with more products\n",
    "- Adding filtering capabilities based on metadata\n",
    "- Integrating with recommendation systems\n",
    "- Adding user personalization features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fd965-ac52-4892-a9bf-5de78ecebd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
