{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this example, you are going to evaluate a scenario of generating customer conversation summaries using generative AI to enhance service quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we are importing necessary packages and setting up a bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing a short text with boto3\n",
    "\n",
    "To learn detail of API request to Amazon Bedrock, this notebook introduces how to create API request and send the request via Boto3.\n",
    "\n",
    "Request Syntax of InvokeModel in Boto3\n",
    "\n",
    "We use InvokeModel API for sending request to a foundation model. Here is an example of API request for sending text to Amazon Titan Text Large. Inference parameters in textGenerationConfig depends on the model that you are about to use. Inference paramerters of Amazon Titan Text are:\n",
    "\n",
    "- maxTokenCount configures the max number of tokens to use in the generated response.\n",
    "- stopSequences is used to make the model stop at a desired point, such as the end of a sentence or a list. The returned response will not contain the stop sequence.\n",
    "- temperature modulates the probability density function for the next tokens, implementing the temperature sampling technique. This parameter can be used to deepen or flatten the density function curve. A lower value results in a steeper curve and more deterministic responses, whereas a higher value results in a flatter curve and more random responses. (float, defaults to 0, max value is 1)\n",
    "- topP controls token choices, based on the probability of the potential choices. If you set Top P below 1.0, the model considers only the most probable options and ignores less probable options. The result is more stable and repetitive completions.\n",
    "\n",
    "response = bedrock.invoke_model(body={\n",
    "                                   \"inputText\": \"<<place your input text here>>\",\n",
    "                                   \"textGenerationConfig\": {\n",
    "                                       \"maxTokenCount\": 4096,\n",
    "                                       \"stopSequences\": [],\n",
    "                                       \"temperature\":0,\n",
    "                                       \"topP\":1\n",
    "                                       },\n",
    "                                },\n",
    "                                modelId=\"amazon.titan-tg1-large\", \n",
    "                                accept=accept, \n",
    "                                contentType=contentType)\n",
    "\n",
    "Writing prompt with text to be summarized\n",
    "\n",
    "In this notebook, you can use any short text whose tokens are less than the maximum token of a foundation model The prompt starts with an instruction \"Please provide a summary of the following text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please provide a summary of the following text. Do not add any information that is not mentioned in the text below.\n",
    "\n",
    "<text>\n",
    "[Agent] Hi, thank you for calling Best Internet company. This is Collin, how may I help. You?\n",
    "[Customer] Hi Collin. So, I'm calling because I have been overcharged, um, my subscription to you guys is supposed to be a flat rate of 50 dollars per month but for some reason I am seeing 75 dollars on my paper bill for the month of March. So, I don't know what's going on. I would really appreciate an explanation on this.\n",
    "[Agent] Sure, I'll be happy to pull up your account now and check the billing details for you. Can I have your account number together with your first and last name?\n",
    "[Customer] Sure it's one two three four five and my full name is Jason Walls.\n",
    "[Agent] Williams. Thank you, Jason. Just give me a few seconds to pull up your account. It was for the month of March this year, right? March 2024?\n",
    "[Customer] That's right.\n",
    "[Agent] Okay let me see that. Okay I have your account pulled up now and I'm only seeing a 50 charge for the month of March this year. Could you recheck your bill and review the amount?\n",
    "[Customer] No. That can't be right. I am literally holding my bill right now and it says March and it says 75 dollars in big bold letters. So, may the charge be moved to Feb or April? I don't know. All I know is that you're overcharging me and it's written on my paper bill.\n",
    "[Agent] Yes, Jason, I also checked your other month's charges this year from January to March 2024 and all of these months you were only charged 50 dollars. Let me just check further though your last year. Oh, although I am seeing 75 dollars charge here but this was way back last year on March 2023. Would you mind checking the year of the billing paper you're holding right now?\n",
    "[Customer] Oh My Goodness! Collin, I'm so, so, sorry to have wasted your time. I really thought this was a recent bill.\n",
    "[Agent] No, don't worry about it, Jason. You're fine.\n",
    "[Customer] This bill was literally on my table this morning. I must have dropped it when I was throwing garbage this morning. So embarrassing, my bad.\n",
    "[Agent] Oh, no problem. It happens, I mean it happens to all of us you know.\n",
    "[Laughter]\n",
    "[Customer] I know, right, anyway Collin I won't waste any more of your time, and thank you so much for your patience.\n",
    "[Agent] You're welcome Jason. Is there anything else that I can help you with today?\n",
    "[Customer] No, that's all Collin. Have a good one.\n",
    "[Agent] Have a good one Jason. Thank you for calling Best Internet. Bye.\n",
    "[Customer] Bye, Collin.\n",
    "</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": prompt, \n",
    "                   \"textGenerationConfig\":{\n",
    "                       \"maxTokenCount\":4096,\n",
    "                       \"stopSequences\":[],\n",
    "                       \"temperature\":0,\n",
    "                       \"topP\":1\n",
    "                   },\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke foundation model via Boto3\n",
    "\n",
    "Here sends the API request to Amazon Bedrock with specifying request parameters modelId, accept, and contentType. Following the prompt, the foundation model in Amazon Bedrock sumamrizes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer calls Best Internet company to complain about being overcharged. The agent checks the customer's account and finds that the subscription is supposed to be a flat rate of 50 dollars per month, but the customer is seeing 75 dollars on their paper bill for the month of March. The agent explains that the charge is from last year and that the customer was only charged 50 dollars for the other months this year. The customer apologizes for wasting the agent's time and thanks them for their patience. The agent assures the customer that it happens to everyone and that there is nothing else that they can help them with. The customer ends the call by thanking the agent and saying goodbye.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'amazon.titan-text-express-v1' # change this to use a different model\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "try:\n",
    "    \n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    print(response_body.get('results')[0].get('outputText'))\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use Claude 3 Sonnet model for the same scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"temperature\":0.5,\n",
    "    \"top_k\":250,\n",
    "    \"top_p\":0.5,\n",
    "    \"stop_sequences\":[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the conversation:\n",
      "\n",
      "The customer, Jason Walls, called Best Internet company thinking he was overcharged $75 instead of the usual $50 monthly fee for March 2024. The agent, Collin, looked up Jason's account and confirmed he was only charged $50 for March 2024. After some back and forth, Jason realized the $75 charge was actually from his bill from March 2023, which he had mistakenly picked up that morning. Jason apologized for the misunderstanding and wasting Collin's time. Collin was understanding and polite throughout the call. In the end, there were no issues with Jason's current billing, and the call ended amicably.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('content')[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "You have now experimented with using boto3 SDK to invoke Amazon Bedrock APIs. Using this API you have seen the use case of generating a summary of call transcript."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
