{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Bedrock APIs: Customer Conversation Summarization with Amazon Bedrock\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to generate customer conversation summaries using Amazon Bedrock APIs. We'll explore how to use foundation models to enhance service quality through automated conversation analysis and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to interact with Amazon Bedrock APIs. We'll explore how to list available foundation models, generate text using the standard API, and use the newer Converse API for multi-turn conversations.In this example, you are going to evaluate a scenario of generating customer conversation summaries using generative AI to enhance service quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- AWS account with Amazon Bedrock access\n",
    "- Access to Claude 3 models\n",
    "- Basic understanding of AWS SDK for Python (boto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the AWS SDK for Python\n",
    "%pip install -U --no-cache-dir boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for JSON handling, AWS SDK, and error handling\n",
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Initialize Bedrock runtime client for invoking foundation models\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Text with Amazon Bedrock\n",
    "\n",
    "To learn details of API requests to Amazon Bedrock, this notebook introduces how to create API requests and send them via Boto3.\n",
    "\n",
    "### Request Syntax of InvokeModel in Boto3\n",
    "\n",
    "We use the `InvokeModel` API for sending requests to a foundation model. Here we'll demonstrate with Amazon Nova Micro and Claude 3.5 Haiku models. Inference parameters depend on the model you are using.\n",
    "\n",
    "**Amazon Nova Micro Inference Parameters:**\n",
    "\n",
    "- **maxTokenCount**: Configures the max number of tokens to use in the generated response\n",
    "- **stopSequences**: Used to make the model stop at a desired point, such as the end of a sentence or list\n",
    "- **temperature**: Modulates the probability density function for next tokens (0-1, lower = more deterministic)\n",
    "- **topP**: Controls token choices based on probability of potential choices (below 1.0 = more stable)\n",
    "\n",
    "```python\n",
    "response = bedrock.invoke_model(\n",
    "    body={\n",
    "        \"inputText\": \"<<place your input text here>>\",\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 4096,\n",
    "            \"stopSequences\": [],\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1\n",
    "        }\n",
    "    },\n",
    "    modelId=\"amazon.nova-micro-v1:0\",\n",
    "    accept=accept,\n",
    "    contentType=contentType\n",
    ")\n",
    "```\n",
    "\n",
    "### Writing Prompt with Text to be Summarized\n",
    "\n",
    "In this notebook, you can use any short text whose tokens are less than the maximum token limit of a foundation model. The prompt starts with an instruction: *\"Please provide a summary of the following text.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt with customer service conversation to be summarized\n",
    "prompt = \"\"\"\n",
    "Please provide a summary of the following text. Do not add any information that is not mentioned in the text below.\n",
    "\n",
    "<text>\n",
    "[Agent] Hi, thank you for calling Best Internet company. This is Collin, how may I help. You?\n",
    "[Customer] Hi Collin. So, I'm calling because I have been overcharged, um, my subscription to you guys is supposed to be a flat rate of 50 dollars per month but for some reason I am seeing 75 dollars on my paper bill for the month of March. So, I don't know what's going on. I would really appreciate an explanation on this.\n",
    "[Agent] Sure, I'll be happy to pull up your account now and check the billing details for you. Can I have your account number together with your first and last name?\n",
    "[Customer] Sure it's one two three four five and my full name is Jason Walls.\n",
    "[Agent] Williams. Thank you, Jason. Just give me a few seconds to pull up your account. It was for the month of March this year, right? March 2024?\n",
    "[Customer] That's right.\n",
    "[Agent] Okay let me see that. Okay I have your account pulled up now and I'm only seeing a 50 charge for the month of March this year. Could you recheck your bill and review the amount?\n",
    "[Customer] No. That can't be right. I am literally holding my bill right now and it says March and it says 75 dollars in big bold letters. So, may the charge be moved to Feb or April? I don't know. All I know is that you're overcharging me and it's written on my paper bill.\n",
    "[Agent] Yes, Jason, I also checked your other month's charges this year from January to March 2024 and all of these months you were only charged 50 dollars. Let me just check further though your last year. Oh, although I am seeing 75 dollars charge here but this was way back last year on March 2023. Would you mind checking the year of the billing paper you're holding right now?\n",
    "[Customer] Oh My Goodness! Collin, I'm so, so, sorry to have wasted your time. I really thought this was a recent bill.\n",
    "[Agent] No, don't worry about it, Jason. You're fine.\n",
    "[Customer] This bill was literally on my table this morning. I must have dropped it when I was throwing garbage this morning. So embarrassing, my bad.\n",
    "[Agent] Oh, no problem. It happens, I mean it happens to all of us you know.\n",
    "[Laughter]\n",
    "[Customer] I know, right, anyway Collin I won't waste any more of your time, and thank you so much for your patience.\n",
    "[Agent] You're welcome Jason. Is there anything else that I can help you with today?\n",
    "[Customer] No, that's all Collin. Have a good one.\n",
    "[Agent] Have a good one Jason. Thank you for calling Best Internet. Bye.\n",
    "[Customer] Bye, Collin.\n",
    "</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON request body for Nova Micro with correct parameters\n",
    "body = json.dumps({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\n",
    "        \"maxTokens\": 4096,\n",
    "        \"temperature\": 0,\n",
    "        \"topP\": 1\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke Foundation Model via Boto3\n",
    "\n",
    "Here we send the API request to Amazon Bedrock by specifying request parameters `modelId`, `accept`, and `contentType`. Following the prompt, the foundation model in Amazon Bedrock summarizes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters and invoke Nova Micro to generate conversation summary\n",
    "modelId = 'amazon.nova-micro-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "try:\n",
    "    # Call Bedrock API to invoke the Nova Micro model\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    # Extract and print the generated summary\n",
    "    print(response_body['output']['message']['content'][0]['text'])\n",
    "    \n",
    "except botocore.exceptions.ClientError as error:\n",
    "    # Handle access denied errors with helpful troubleshooting links\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Claude 3.5 Haiku Model\n",
    "\n",
    "Let's try to use Claude 3.5 Haiku model for the same scenario to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON request body for Claude 3.5 Haiku with different parameter structure\n",
    "body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"temperature\":0.5,\n",
    "    \"top_k\":250,\n",
    "    \"top_p\":0.5,\n",
    "    \"stop_sequences\":[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke Claude 3.5 Haiku model using inference profile\n",
    "modelId = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# Print Claude's response\n",
    "print(response_body.get('content')[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have now experimented with using the boto3 SDK to invoke Amazon Bedrock APIs. Using this API, you have seen the use case of generating a summary of call transcripts with different foundation models:\n",
    "\n",
    "- **Amazon Nova Micro**: Provides fast, cost-effective summaries with good accuracy\n",
    "- **Claude 3.5 Haiku**: Offers quick, efficient summaries with excellent performance\n",
    "\n",
    "Both models successfully identified the key points of the customer service conversation and provided accurate summaries without adding information not present in the original text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
