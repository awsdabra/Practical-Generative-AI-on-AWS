{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Knowledge Bases: Knowledge Bases for Amazon Bedrock\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to create and configure Amazon Bedrock Knowledge Bases for retrieval-augmented generation (RAG) applications. We'll explore how to ingest documents, create vector embeddings, and build intelligent search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to build and use a Knowledge Base with Amazon Bedrock, enabling semantic search and question-answering over your documents. We'll use OpenSearch Serverless as the vector store, Amazon Titan Text Embeddings for embedding generation, and Claude 3 Sonnet for answering queries based on the retrieved information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- AWS account with Amazon Bedrock access\n",
    "- S3 bucket with document data\n",
    "- Access to Amazon Titan Embeddings and Claude 3 models\n",
    "- Required IAM permissions for OpenSearch Serverless and knowledge base creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary packages for AWS Bedrock and OpenSearch integration\n",
    "\n",
    "%pip install --upgrade boto3      # AWS SDK for Python\n",
    "%pip install --upgrade botocore   # Low-level AWS service access\n",
    "%pip install --upgrade opensearch-py  # OpenSearch Python client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# AWS SDK imports\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Utility imports\n",
    "import pprint\n",
    "from utility import (\n",
    "    create_bedrock_execution_role, \n",
    "    create_oss_policy_attach_bedrock_execution_role, \n",
    "    create_policies_in_oss, \n",
    "    interactive_sleep\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client and Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AWS session and get region information\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "\n",
    "# Create AWS service clients\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', region_name=region_name)\n",
    "\n",
    "# Configuration parameters\n",
    "service = 'aoss'  # Amazon OpenSearch Serverless\n",
    "bucket_name = \"\"  # ‚ö†Ô∏è **IMPORTANT**: Replace with your S3 bucket name\n",
    "\n",
    "# Pretty printer for formatted output\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "print(f\"üåç **Region**: {region_name}\")\n",
    "print(f\"üì¶ **Service**: {service}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSearch Serverless Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Role Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vector store configuration\n",
    "vector_store_name = 'bedrock-sample-rag'  # Name for the OpenSearch collection\n",
    "index_name = 'bedrock-sample-rag-index'   # Name for the vector index\n",
    "\n",
    "# Create OpenSearch Serverless client\n",
    "aoss_client = boto3_session.client('opensearchserverless', region_name=region_name)\n",
    "\n",
    "# Create IAM execution role for Bedrock Knowledge Base\n",
    "print(\"üîê Creating Bedrock execution role...\")\n",
    "bedrock_kb_execution_role = create_bedrock_execution_role(bucket_name=bucket_name)\n",
    "bedrock_kb_execution_role_arn = bedrock_kb_execution_role['Role']['Arn']\n",
    "\n",
    "print(f\"‚úÖ **Execution Role ARN**: {bedrock_kb_execution_role_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch Policies and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create security, network and data access policies within OpenSearch Serverless\n",
    "print(\"üõ°Ô∏è Creating OpenSearch Serverless policies...\")\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(\n",
    "    vector_store_name=vector_store_name,\n",
    "    aoss_client=aoss_client,\n",
    "    bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn\n",
    ")\n",
    "\n",
    "# Create the vector search collection\n",
    "print(f\"üìä Creating vector collection: {vector_store_name}...\")\n",
    "collection = aoss_client.create_collection(\n",
    "    name=vector_store_name,\n",
    "    type='VECTORSEARCH'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Collection creation initiated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display collection details\n",
    "print(\"üìã **Collection Details**:\")\n",
    "pp.pprint(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract collection ID and construct the endpoint URL\n",
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = f\"{collection_id}.{region_name}.aoss.amazonaws.com\"\n",
    "\n",
    "print(f\"üåê **Collection Endpoint**: {host}\")\n",
    "print(f\"üÜî **Collection ID**: {collection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role Policy Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and attach OpenSearch Serverless access policy to Bedrock execution role\n",
    "print(\"üîó Attaching OpenSearch access policy to Bedrock role...\")\n",
    "create_oss_policy_attach_bedrock_execution_role(\n",
    "    collection_id=collection_id,\n",
    "    bedrock_kb_execution_role=bedrock_kb_execution_role\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Policy attachment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Index Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenSearch Python client\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "# Set up AWS authentication for OpenSearch\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWSV4SignerAuth(credentials, region_name, service)\n",
    "\n",
    "# Define index name and configuration\n",
    "index_name = \"bedrock-sample-index\"\n",
    "\n",
    "# Vector index schema configuration\n",
    "body_json = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": \"true\"  # Enable k-nearest neighbor search\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            # Vector field for embeddings\n",
    "            \"vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,  # Titan embedding dimensions\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",      # Hierarchical Navigable Small World\n",
    "                    \"engine\": \"faiss\",    # Facebook AI Similarity Search\n",
    "                    \"space_type\": \"l2\"    # L2/Euclidean distance\n",
    "                }\n",
    "            },\n",
    "            # Text content field\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            # Metadata field\n",
    "            \"text-metadata\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create OpenSearch client with AWS authentication\n",
    "print(\"üîß Setting up OpenSearch client...\")\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Wait for data access rules to be enforced\n",
    "print(\"‚è≥ Waiting for data access rules to be enforced (120 seconds)...\")\n",
    "time.sleep(120)\n",
    "print(\"‚úÖ Ready to create index!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Index Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóëÔ∏è **Optional**: Delete existing index if needed\n",
    "# Uncomment the line below if you encounter errors or need to recreate the index\n",
    "# oss_client.indices.delete(index=index_name)\n",
    "# print(f\"üóëÔ∏è Deleted existing index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector index\n",
    "# ‚ö†Ô∏è **Important**: Collection must be in ACTIVE state before creating an index\n",
    "print(f\"‚ú® Creating vector index: {index_name}...\")\n",
    "\n",
    "try:\n",
    "    response = oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "    print(\"‚úÖ **Index Creation Response**:\")\n",
    "    pp.pprint(response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå **Error creating index**: {str(e)}\")\n",
    "    print(\"üí° **Tip**: Ensure the collection is in ACTIVE state and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data source directory\n",
    "data_root = \"data/\"\n",
    "\n",
    "# Create S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "def uploadDirectory(path, bucket_name):\n",
    "    \"\"\"\n",
    "    Upload all files from a local directory to S3 bucket.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Local directory path containing files to upload\n",
    "        bucket_name (str): Target S3 bucket name\n",
    "    \"\"\"\n",
    "    uploaded_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            try:\n",
    "                s3_client.upload_file(local_path, bucket_name, file)\n",
    "                uploaded_files.append(file)\n",
    "                print(f\"üì§ Uploaded: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to upload {file}: {str(e)}\")\n",
    "    \n",
    "    return uploaded_files\n",
    "\n",
    "# Upload documents to S3\n",
    "print(f\"üì§ **Uploading files from {data_root} to bucket: {bucket_name}**\")\n",
    "\n",
    "if bucket_name:\n",
    "    uploaded_files = uploadDirectory(data_root, bucket_name)\n",
    "    print(f\"‚úÖ **Upload completed!** {len(uploaded_files)} files uploaded.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è **Warning**: Please set the bucket_name variable before running this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Base Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize opensearch serverless configuration including collection ARN, index name, vector field, text field and metadata field.\n",
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"]['arn'],\n",
    "            \"vectorIndexName\": index_name,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Ingest/chunking strategy - How to ingest data from the data source\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"overlapPercentage\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "# The data source to ingest documents from, into the opensearch serverless knowledge base index\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket_name}\",\n",
    "}\n",
    "\n",
    "# The embedding model used by Bedrock to embed ingested documents, and realtime prompts\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "\n",
    "name = \"bedrock-sample-knowledge-base\"\n",
    "description = \"FAQs\"\n",
    "roleArn = bedrock_kb_execution_role_arn\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the knowledge base\n",
    "\n",
    "def create_knowledge_base():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        roleArn = roleArn,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        }\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    kb = create_knowledge_base()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")\n",
    "\n",
    "pp.pprint(kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Knowledge Base info\n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb['knowledgeBaseId'])\n",
    "pp.pprint(get_kb_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source in knowledge base \n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = name,\n",
    "    description = description,\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "ds = create_ds_response[\"dataSource\"]\n",
    "pp.pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data source info\n",
    "bedrock_agent_client.get_data_source(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Ingestion Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an ingestion job\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])\n",
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job ID\n",
    "get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "      dataSourceId = ds[\"dataSourceId\"],\n",
    "      ingestionJobId = job[\"ingestionJobId\"]\n",
    ")\n",
    "job = get_job_response[\"ingestionJob\"]\n",
    "\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the knowledge base Id in bedrock, that corresponds to the opensearch index in the collection we created before, we will use it for the invocation later\n",
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "pp.pprint(kb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out KB using RetrieveAndGenerate API\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bedrock_llm_with_knowledge_base(query: str, model_arn: str, kb_id: str) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I find out if you have a product in stock?\"\n",
    "\n",
    "model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id}'\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "generated_text = response['output']['text']\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "print(f\"---------- Generated using {model_id[0]}:\")\n",
    "pp.pprint(generated_text )\n",
    "print(f'---------- The citations for the response generated by {model_id[0]}:')\n",
    "pp.pprint(contexts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've successfully built a fully functional Knowledge Base using Amazon Bedrock and OpenSearch Serverless. This implementation demonstrates an end-to-end Retrieval Augmented Generation (RAG) system that can answer questions based on your custom document collection.\n",
    "\n",
    "Key components we established:\n",
    "\n",
    "1. **Vector Store**: We set up OpenSearch Serverless as our vector database, configuring the proper schema for storing embeddings and text.\n",
    "\n",
    "2. **Access Control**: We created the necessary IAM roles and policies to allow secure interaction between Bedrock and OpenSearch Serverless.\n",
    "\n",
    "3. **Document Processing**: We implemented a chunking strategy that breaks documents into fixed-size chunks with overlap for better context preservation.\n",
    "\n",
    "4. **Embedding Generation**: We configured the system to use Amazon Titan Text Embeddings to convert document chunks into vector representations.\n",
    "\n",
    "5. **Query Processing**: We demonstrated how to use the RetrieveAndGenerate API to retrieve relevant information and generate accurate answers using Claude 3 Sonnet.\n",
    "\n",
    "This Knowledge Base architecture provides several advantages:\n",
    "\n",
    "- **Scalability**: OpenSearch Serverless automatically scales to accommodate growing document collections\n",
    "- **Semantic Understanding**: Vector search finds contextually relevant information, not just keyword matches\n",
    "- **Source Attribution**: Citations provide transparency about which documents informed the response\n",
    "- **Up-to-date Knowledge**: Foundation models are enhanced with your specific, current information\n",
    "\n",
    "Potential applications include:\n",
    "- Customer support knowledge bases\n",
    "- Employee portals for company policies and procedures\n",
    "- Research assistants for analyzing large document collections\n",
    "- Product documentation and FAQ systems\n",
    "\n",
    "This approach combines the best of both worlds: the vast knowledge and language capabilities of foundation models with the accuracy and specificity of your proprietary documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
