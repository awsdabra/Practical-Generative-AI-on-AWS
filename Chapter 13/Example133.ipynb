{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916b7206-4f41-4e9e-9321-d1c4160f970e",
   "metadata": {},
   "source": [
    "# Chapter 13 - SageMaker JumpStart: Fine-tuning CodeLlama with SageMaker JumpStart for Code Generation\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to fine-tune CodeLlama model using Amazon SageMaker JumpStart for code generation tasks. We'll explore how to adapt the model for specific programming languages and use cases, then deploy it for automated code generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4261e-1c6e-4ccb-962c-d4befb966f25",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to fine-tune a CodeLlama model on programming-related instruction data using Amazon SageMaker JumpStart. We'll leverage the Dolphin Coder dataset to enhance the model's coding capabilities, deploy it as a SageMaker endpoint, and compare the performance between the original and fine-tuned models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369afb36-514e-4bb4-b47b-073ba3439794",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- AWS account with SageMaker access\n",
    "- Appropriate permissions for JumpStart models\n",
    "- SageMaker Execution role with S3 access\n",
    "- G5 instance quota in your AWS account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc9d17-5909-4723-ae55-385785d8d745",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44582f5-48e5-43b6-973c-6ebdaea90db7",
   "metadata": {},
   "source": [
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d07608-428a-4956-bcc7-397ef25e87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade sagemaker jmespath datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b12b3d-dc22-43d6-babf-f17a6871b273",
   "metadata": {},
   "source": [
    "### Import Libraries and Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa559c5-56f8-4701-96bc-0ba13a4d1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "\n",
    "try:\n",
    "    dropdown = Dropdown(\n",
    "        options=list_jumpstart_models(\"search_keywords includes Text Generation\"),\n",
    "        value=\"meta-textgeneration-llama-codellama-7b\",\n",
    "        description=\"Select a JumpStart text generation model:\",\n",
    "        style={\"description_width\": \"initial\"},\n",
    "        layout={\"width\": \"max-content\"},\n",
    "    )\n",
    "    display(dropdown)\n",
    "except:\n",
    "    dropdown = None\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf3825-1234-4671-aeac-6da099a5b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dropdown:\n",
    "    model_id = dropdown.value\n",
    "else:\n",
    "    model_id = \"meta-textgeneration-llama-codellama-7b\"\n",
    "model_version = \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bd0b2-f638-423d-8ddd-ff627f1e5ed4",
   "metadata": {},
   "source": [
    "## Deploy Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b395e-d74f-4da6-86fa-7565589a53a7",
   "metadata": {},
   "source": [
    "### Initialize and Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d03037-4b7a-4067-ae09-daf217823f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model = JumpStartModel(model_id=model_id, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c191a1-7340-4086-9d39-0422459790c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    accept_eula=True\n",
    ")  # please change `accept_eula` to be True to accept EULA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d1ef1-e5b6-4dbf-b09d-5a6037ad3a0b",
   "metadata": {},
   "source": [
    "### Test Base Model with Example Payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc6b7e-80ed-4d7e-9743-e62d1233d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_payloads = model.retrieve_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866869e7-2e98-4b14-bfc8-17e628b08155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jmespath\n",
    "\n",
    "\n",
    "for payload in example_payloads:\n",
    "    response = predictor.predict(payload.body)\n",
    "    generated_text = jmespath.search(payload.raw_payload[\"output_keys\"][\"generated_text\"], response)\n",
    "    print(\"Input:\\n\", payload.body[payload.prompt_key])\n",
    "    print(\"Output:\\n\", generated_text.strip())\n",
    "    print(\"\\n===============\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a6111-2472-4e4c-82c5-6f27bfca246c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189af884-002a-482a-819c-91233998b418",
   "metadata": {},
   "source": [
    "### Load and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55e1bc-f383-49cc-b9ce-f654bfe51829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dolphin = load_dataset(\"cognitivecomputations/dolphin-coder\", split=\"train\")\n",
    "\n",
    "# We split the dataset into two where test data is used to evaluate at the end.\n",
    "train_and_test_dataset = dolphin.train_test_split(test_size=0.9, seed=0)\n",
    "\n",
    "# Dumping the training data to a local file to be used for training.\n",
    "train_and_test_dataset[\"train\"].to_json(\"train.jsonl\")\n",
    "train_and_test_dataset[\"test\"].select(range(10)).to_json(\"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b113d21-0493-4151-a3f2-c5a8b2ea84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ced46-7daa-4f24-b4a6-bb9b9bf31ffb",
   "metadata": {},
   "source": [
    "### Create Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149755b8-5882-4e51-8562-2d4ca969ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "template = {\n",
    "    \"prompt\": \"\"\"{system_prompt}\n",
    "\n",
    "### Input:\n",
    "{question}\n",
    "\"\"\",\n",
    "    \"completion\": \" {response}\",\n",
    "}\n",
    "with open(\"template.json\", \"w\") as f:\n",
    "    json.dump(template, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb71c6-eeb9-473d-82c4-1986a38274de",
   "metadata": {},
   "source": [
    "### Upload Training Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89659f92-7e31-4184-bf21-73f3db76afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "import sagemaker\n",
    "import random\n",
    "\n",
    "output_bucket = sagemaker.Session().default_bucket()\n",
    "local_data_file = \"train.jsonl\"\n",
    "train_data_location = f\"s3://{output_bucket}/dolphin_coder_dataset\"\n",
    "S3Uploader.upload(local_data_file, train_data_location)\n",
    "S3Uploader.upload(\"template.json\", train_data_location)\n",
    "print(f\"Training data: {train_data_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e045ef-f859-4a1f-be35-714a9a56c987",
   "metadata": {},
   "source": [
    "## Model Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc7dcf-86ac-477c-a0b7-fa312cc43387",
   "metadata": {},
   "source": [
    "### Configure Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c0a4b-0235-4464-9246-9cac77684e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "my_hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=model_id, model_version=model_version\n",
    ")\n",
    "\n",
    "print(my_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65858f7-28e9-4510-94dd-380bdeda0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hyperparameters[\"epoch\"] = \"1\"\n",
    "print(my_hyperparameters)\n",
    "\n",
    "hyperparameters.validate(\n",
    "    model_id=model_id, model_version=model_version, hyperparameters=my_hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bb207-bdd3-426a-a99c-c54e3f7adfca",
   "metadata": {},
   "source": [
    "### Initialize and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5397d51-54c1-4828-9ef4-21a13fb281a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "\n",
    "\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    hyperparameters=my_hyperparameters,\n",
    "    instance_type=\"ml.g5.24xlarge\",\n",
    "    environment={\n",
    "        \"accept_eula\": \"true\"\n",
    "    },  # please change `accept_eula` to be `true` to accept EULA.\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": train_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eaeb0c-c888-4c21-ac6f-8454487f2d4d",
   "metadata": {},
   "source": [
    "### Deploy Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6528f-28e3-4919-8d4d-582288ca9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_predictor = estimator.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a39f31-aa01-4431-9841-356d80556b46",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461ecf3-0a16-4c56-ba56-66611882fc56",
   "metadata": {},
   "source": [
    "### Compare Original and Fine-tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd36723-dbcf-4228-9433-0a214885fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test.jsonl\")[\"train\"]\n",
    "prompt_inference = template[\"prompt\"]\n",
    "inputs, ground_truth_responses, responses_before_finetuning, responses_after_finetuning = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "\n",
    "def predict_and_print(datapoint):\n",
    "    # For instruction fine-tuning, we insert a special key between input and output\n",
    "    input_output_demarkation_key = \"\\n\\n### Response:\\n\"\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": prompt_inference.format(\n",
    "            system_prompt=datapoint[\"system_prompt\"], question=datapoint[\"question\"]\n",
    "        )\n",
    "        + input_output_demarkation_key,\n",
    "        \"parameters\": {\"max_new_tokens\": 100},\n",
    "    }\n",
    "    inputs.append(payload[\"inputs\"])\n",
    "    ground_truth_responses.append(datapoint[\"response\"])\n",
    "    pretrained_response = predictor.predict(payload)\n",
    "    responses_before_finetuning.append(pretrained_response[0][\"generated_text\"])\n",
    "    finetuned_response = finetuned_predictor.predict(payload)\n",
    "    responses_after_finetuning.append(finetuned_response[0][\"generated_text\"])\n",
    "\n",
    "\n",
    "try:\n",
    "    for i, datapoint in enumerate(test_dataset.select(range(5))):\n",
    "        predict_and_print(datapoint)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Inputs\": inputs,\n",
    "            \"Ground Truth\": ground_truth_responses,\n",
    "            \"Response from non-finetuned model\": responses_before_finetuning,\n",
    "            \"Response from fine-tuned model\": responses_after_finetuning,\n",
    "        }\n",
    "    )\n",
    "    display(HTML(df.to_html()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79985f41-3c0d-4141-aeeb-6734e1ba092d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've successfully fine-tuned CodeLlama on programming instruction data using SageMaker JumpStart. The process involved:\n",
    "\n",
    "1. Deploying a pre-trained CodeLlama model as a baseline\n",
    "2. Preparing the Dolphin Coder dataset for fine-tuning\n",
    "3. Configuring and executing the fine-tuning job\n",
    "4. Deploying the fine-tuned model as an endpoint\n",
    "5. Comparing the performance between the original and fine-tuned models\n",
    "\n",
    "The results demonstrate how fine-tuning can significantly improve the model's ability to follow coding instructions and generate more accurate and relevant code. This approach can be extended to other domains by swapping out the training data and adjusting hyperparameters.\n",
    "\n",
    "For production deployments, consider:\n",
    "- Using a larger training dataset for better results\n",
    "- Experimenting with different hyperparameters like learning rate and batch size\n",
    "- Implementing auto-scaling for your endpoint to handle variable traffic\n",
    "- Setting up monitoring to track model performance over time\n",
    "- Optimizing the deployment for cost efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213751ca-6397-4d05-a2da-5b3667e25551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
