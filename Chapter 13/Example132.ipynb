{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc029c6-edb9-404c-bb9c-4cabdae64a1e",
   "metadata": {},
   "source": [
    "# Chapter 13 - SageMaker JumpStart: Fine-tuning and Inference with GPT-J 6B on SageMaker JumpStart\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to fine-tune and deploy GPT-J 6B model using Amazon SageMaker JumpStart. We'll explore the complete workflow from model selection and fine-tuning to deployment and inference for various natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a4e0e-4358-4b3d-9394-bef96e0381f6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Hugging Face GPT-J 6B model using Amazon SageMaker JumpStart.\n",
    "We'll leverage pre-existing SEC financial data to train the model to better understand and generate\n",
    "financial text. After fine-tuning, we'll deploy the model to a SageMaker endpoint for real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de7cac-08b1-4a19-8b87-d2b4287edd1e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- AWS account with SageMaker access\n",
    "- Sufficient permissions to access JumpStart models\n",
    "- IAM role with appropriate SageMaker execution permissions\n",
    "- Familiarity with Python and basic machine learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b7ea3-15bb-4f18-a10d-09df34dfb337",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612946d-1bb8-491d-8102-fefad409ad87",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752ebdb-2177-4d1e-af94-3e848c332e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the JumpStart model we want to fine-tune\n",
    "model_id = \"huggingface-textgeneration1-gpt-j-6b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238d4e1-fd16-4cd9-914a-2d4a052e5a91",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ab7d7-ed47-456c-b42f-4d8a7e7444f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages for working with SageMaker JumpStart\n",
    "import json\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "from sagemaker.jumpstart.utils import get_jumpstart_content_bucket\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff42a0-5350-4580-af11-5896e6df392e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67d75a-e3f1-4d4f-acb2-3e6975b9f9c8",
   "metadata": {},
   "source": [
    "### Locate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a6377-5b4f-420b-ae15-50f45b46b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = get_jumpstart_content_bucket()\n",
    "data_prefix = \"training-datasets/sec_data\"\n",
    "# Define paths to training and validation datasets\n",
    "training_dataset_s3_path = f\"s3://{data_bucket}/{data_prefix}/train/\"\n",
    "validation_dataset_s3_path = f\"s3://{data_bucket}/{data_prefix}/validation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c10a1e-64ff-4a57-a5ea-81f35ecc87f1",
   "metadata": {},
   "source": [
    "## Model Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca48ac-843c-4eef-956b-075e277e3629",
   "metadata": {},
   "source": [
    "### Configure Fine-tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f62b6-6435-40f7-8043-06e37466177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the JumpStart estimator with our desired hyperparameters\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    hyperparameters={\"epoch\": \"3\", \"per_device_train_batch_size\": \"4\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff8995-69cb-4a6c-9734-e6b2e9b51082",
   "metadata": {},
   "source": [
    "### Execute Fine-tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aca251-ad0f-4157-b3a2-cfc6f7506591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now fit the estimator by providing training data to the train channel\n",
    "\n",
    "estimator.fit(\n",
    "    {\"train\": training_dataset_s3_path, \"validation\": validation_dataset_s3_path}, logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a4df1-c4ac-4736-98eb-9e3bc8c5f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b1c7b-5565-4621-a0cb-882cc0a53446",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e07efa-7ff2-4b3f-a2e5-b89cd4f93381",
   "metadata": {},
   "source": [
    "### Deploy to SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f58c83-44e1-4f12-b52b-31e212724a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy our fine-tuned model to a real-time endpoint\n",
    "predictor = estimator.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e6b8b-132a-41e0-8c2c-8fdd69a19a2d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164421e2-1c21-4542-aa5e-6451d428ffd2",
   "metadata": {},
   "source": [
    "### Test with Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb840081-678d-4763-9c8d-0baaf555d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample payload to test the model\n",
    "payload = {\"inputs\": \"This Form 10-K report shows that\", \"parameters\": {\"max_new_tokens\": 400}}\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e21dc8-f581-44b0-85f6-1bbea93c8d7f",
   "metadata": {},
   "source": [
    "### Alternative: Using Existing Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87637e61-e7ed-4381-adaa-f8683541c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have a deployed endpoint, you can test it directly\n",
    "endpoint_name = \"jumpstart-dft-hf-textgeneration1-gp-20240712-023109\"\n",
    "payload = {\"inputs\": \"This Form 10-K report shows that\", \"parameters\": {\"max_new_tokens\": 400}}\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "# Invoke the endpoint with our test prompt\n",
    "response = client.invoke_endpoint(\n",
    "  EndpointName=endpoint_name,\n",
    "  Body=json.dumps(payload),\n",
    "  ContentType='application/json'\n",
    ")\n",
    "# Parse and display the generated text\n",
    "result = json.loads(response['Body'].read().decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0de9c-e2a0-436f-a1b0-972f6e0b7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55463607-45b1-4bf9-ac67-2eca0e6841bb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've successfully fine-tuned GPT-J 6B on financial SEC data using SageMaker JumpStart.\n",
    "This demonstrates how to leverage pre-trained models and customize them for specific domains without\n",
    "requiring extensive infrastructure management or deep machine learning expertise.\n",
    "\n",
    "Key accomplishments:\n",
    "1. Configured and initiated a fine-tuning job on a large language model (6B parameters)\n",
    "2. Used domain-specific financial data to adapt the model to SEC filings\n",
    "3. Deployed the model to a SageMaker endpoint for real-time inference\n",
    "4. Tested the model with sample financial text prompts\n",
    "\n",
    "This approach can be extended to other domains by swapping out the training data and adjusting\n",
    "hyperparameters. The deployed model can be integrated into applications that require financial\n",
    "text generation, summarization, or completion capabilities.\n",
    "\n",
    "For production deployments, consider:\n",
    "- Optimizing endpoint configurations for cost and performance\n",
    "- Implementing proper monitoring and logging\n",
    "- Setting up auto-scaling to handle variable traffic patterns\n",
    "- Adding proper request validation and error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd6fba-91cb-43d1-9f6f-923632122ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a1484-d4de-419e-9af9-b093d4c98fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
