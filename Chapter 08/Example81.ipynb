{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing necessary packages\n",
    "!pip install datasets==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup bucket, IAM role and policy\n",
    "iam = boto3.client(\"iam\")\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Create the new bucket\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"bedrock-finetuning-{account_id}\"\n",
    "s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "# Create IAM Role and Policy\n",
    "role = iam.create_role(\n",
    "    RoleName=f\"Bedrock-Finetuning-Role-{account_id}\",\n",
    "    AssumeRolePolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"bedrock.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ] \n",
    "    })\n",
    ")['Role']['RoleName']\n",
    "\n",
    "policy_arn = iam.create_policy(\n",
    "    PolicyName=\"Bedrock-Finetuning-Role-Policy\",\n",
    "    PolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:PutObject\",\n",
    "                    \"s3:ListBucket\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:s3:::{bucket_name}\",\n",
    "                    f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")['Policy']['Arn']\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role,\n",
    "    PolicyArn=policy_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the dataset, modify it, and uploading to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data from huggingface dataset\n",
    "#Citation - https://huggingface.co/datasets/knkarthick/dialogsum\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"knkarthick/dialogsum\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.remove_columns(\"id\")\n",
    "dataset = dataset.remove_columns(\"summary\")\n",
    "dataset = dataset.select(range(10000))\n",
    "\n",
    "# We split the dataset into two where test data is used to evaluate at the end.\n",
    "train_and_validation_dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "dataset_dir = \"dataset\"\n",
    "def format_save_dataset(filename, dataset):\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    with open(f\"{dataset_dir}/{filename}\", \"w\") as f:\n",
    "        for i in dataset:\n",
    "            dialogue = i[\"dialogue\"]\n",
    "            topic = i[\"topic\"]\n",
    "            template = {\n",
    "                \"prompt\": f\"Identify the key topic representing the dialoge. \\n\\nDialogue: {dialogue}\",\n",
    "                \"completion\": f\"{topic}\",\n",
    "            }\n",
    "            json.dump(template, f)\n",
    "            f.write('\\n')\n",
    "    return \n",
    "\n",
    "# format_save_dataset(\"fulldataset.jsonl\", dataset)\n",
    "format_save_dataset(\"train.jsonl\", train_and_validation_dataset[\"train\"])\n",
    "format_save_dataset(\"validation.jsonl\", train_and_validation_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset to S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"bedrock-finetuning-{account_id}\"\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(full_path, dataset_dir)\n",
    "        s3.upload_file(full_path, bucket_name, relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the datasets are uploaded to S3, we are ready to create a fine-tuning job to start model customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name='bedrock')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "datetime_string = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "customizationType = \"FINE_TUNING\"\n",
    "customModelName = \"custom-titan-lite-model\"\n",
    "baseModelIdentifier = \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\"\n",
    "roleArn=f\"arn:aws:iam::{account_id}:role/Bedrock-Finetuning-Role-{account_id}\"\n",
    "jobName=f\"Titan-Lite-Finetune-Job-{datetime_string}\"\n",
    "hyperParameters = {\n",
    "        \"epochCount\": \"1\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \".0001\",\n",
    "        \"learningRateWarmupSteps\": \"0\"\n",
    "}\n",
    "\n",
    "# Create job\n",
    "response_ft = bedrock.create_model_customization_job(\n",
    "    jobName=jobName,\n",
    "    customModelName=customModelName,\n",
    "    customizationType=customizationType,\n",
    "    roleArn=roleArn,\n",
    "    baseModelIdentifier=baseModelIdentifier,\n",
    "    hyperParameters=hyperParameters,\n",
    "    trainingDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/train.jsonl\"},\n",
    "    validationDataConfig={'validators': [ {\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/validation.jsonl\"} ]},\n",
    "    outputDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/finetuning-output\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobArn = response_ft.get('jobArn')\n",
    "print(jobArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the customized model would take few hours, so periodically check the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the job status, wait until it is \"Complete\"\n",
    "status = bedrock.get_model_customization_job(jobIdentifier=jobName)[\"status\"]\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we need to purchase provisioned throughput before we can start using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purchase provisioned throughput\n",
    "response_pt = bedrock.create_provisioned_model_throughput(\n",
    "    modelId=customModelName,\n",
    "    provisionedModelName=\"ProvisionedCustomTitanLite\",\n",
    "    modelUnits=1\n",
    ")\n",
    "\n",
    "provisionedModelArn = response_pt.get('provisionedModelArn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime=boto3.client(service_name='bedrock-runtime')\n",
    "prompt =\"ENTER_PROMPT\"\n",
    "\n",
    "body = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.5,\n",
    "    \"p\": 0.9,\n",
    "    \"max_tokens\": 512,\n",
    "}\n",
    "\n",
    "response = bedrock_runtime.invoke_model(\n",
    "\tmodelId=provisionedModelArn,\n",
    "    body=json.dumps(body)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
