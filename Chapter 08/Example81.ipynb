{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 - Custom Models: Fine-tuning on Amazon Bedrock\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to fine-tune foundation models on Amazon Bedrock for specialized tasks. We'll walk through the complete process of customizing Amazon Titan Text Lite to perform dialogue topic identification and other domain-specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates how to fine-tune foundation models on Amazon Bedrock for specialized tasks. We'll walk through the complete process of customizing Amazon Titan Text Lite to perform dialogue topic identification. This approach allows you to create custom AI models tailored to your specific use cases while leveraging the power of pre-trained foundation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- AWS account with Amazon Bedrock access\n",
    "- Permissions to create IAM roles and S3 buckets\n",
    "- Access to Amazon Titan Text Lite model\n",
    "- Python environment with required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the HuggingFace datasets library for data processing\n",
    "!pip install datasets==2.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for AWS services and data processing\n",
    "import boto3      # AWS SDK for Python\n",
    "import json       # JSON data handling\n",
    "import datetime   # Timestamp generation\n",
    "import os         # File system operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Infrastructure Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Bucket and IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AWS clients\n",
    "iam = boto3.client(\"iam\")\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Get current AWS account ID for unique resource naming\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"bedrock-finetuning-{account_id}\"\n",
    "\n",
    "# Create S3 bucket for storing training data and model outputs\n",
    "print(f\"Creating S3 bucket: {bucket_name}\")\n",
    "s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "# Create IAM role that Bedrock can assume for fine-tuning\n",
    "role_name = f\"Bedrock-Finetuning-Role-{account_id}\"\n",
    "print(f\"Creating IAM role: {role_name}\")\n",
    "\n",
    "role = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"bedrock.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ] \n",
    "    })\n",
    ")[\"Role\"][\"RoleName\"]\n",
    "\n",
    "# Create IAM policy with S3 permissions for the training bucket\n",
    "policy_arn = iam.create_policy(\n",
    "    PolicyName=\"Bedrock-Finetuning-Role-Policy\",\n",
    "    PolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",      # Read training data\n",
    "                    \"s3:PutObject\",      # Write model outputs\n",
    "                    \"s3:ListBucket\"      # List bucket contents\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:s3:::{bucket_name}\",\n",
    "                    f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")[\"Policy\"][\"Arn\"]\n",
    "\n",
    "# Attach the policy to the role\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role,\n",
    "    PolicyArn=policy_arn\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AWS infrastructure setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DialogSum dataset from HuggingFace\n",
    "# Citation: https://huggingface.co/datasets/knkarthick/dialogsum\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"üì• Loading DialogSum dataset from HuggingFace...\")\n",
    "ds = load_dataset(\"knkarthick/dialogsum\", split=\"train\")\n",
    "print(f\"Dataset loaded with {len(ds)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare the dataset\n",
    "print(\"üîß Processing dataset...\")\n",
    "\n",
    "# Remove unnecessary columns (we only need 'dialogue' and 'topic')\n",
    "dataset = ds.remove_columns(\"id\")\n",
    "dataset = dataset.remove_columns(\"summary\")\n",
    "\n",
    "# Use a subset of 10,000 examples for faster training\n",
    "dataset = dataset.select(range(10000))\n",
    "print(f\"Using {len(dataset)} examples for training\")\n",
    "\n",
    "# Split dataset: 90% training, 10% validation\n",
    "train_and_validation_dataset = dataset.train_test_split(test_size=0.1)\n",
    "print(f\"Training examples: {len(train_and_validation_dataset['train'])}\")\n",
    "print(f\"Validation examples: {len(train_and_validation_dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create directory for dataset files\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "def format_save_dataset(filename, dataset):\n",
    "    \"\"\"\n",
    "    Convert dataset to JSONL format required by Bedrock fine-tuning.\n",
    "    Each line contains a prompt-completion pair for topic identification.\n",
    "    \"\"\"\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{dataset_dir}/{filename}\", \"w\") as f:\n",
    "        for i in dataset:\n",
    "            dialogue = i[\"dialogue\"]\n",
    "            topic = i[\"topic\"]\n",
    "            \n",
    "            # Format as prompt-completion pair for fine-tuning\n",
    "            template = {\n",
    "                \"prompt\": f\"Identify the key topic representing the dialogue. \\n\\nDialogue: {dialogue}\",\n",
    "                \"completion\": f\"{topic}\",\n",
    "            }\n",
    "            \n",
    "            # Write each example as a separate JSON line\n",
    "            json.dump(template, f)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    print(f\"‚úÖ Saved {filename} with {len(dataset)} examples\")\n",
    "\n",
    "# Save training and validation datasets\n",
    "format_save_dataset(\"train.jsonl\", train_and_validation_dataset[\"train\"])\n",
    "format_save_dataset(\"validation.jsonl\", train_and_validation_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload formatted datasets to S3 bucket\n",
    "print(\"üì§ Uploading datasets to S3...\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"bedrock-finetuning-{account_id}\"\n",
    "\n",
    "# Upload all files in the dataset directory\n",
    "uploaded_files = []\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(full_path, dataset_dir)\n",
    "        \n",
    "        # Upload file to S3\n",
    "        s3.upload_file(full_path, bucket_name, relative_path)\n",
    "        uploaded_files.append(relative_path)\n",
    "        print(f\"  ‚úÖ Uploaded: {relative_path}\")\n",
    "\n",
    "print(f\"üìä Dataset upload complete! Files available at s3://{bucket_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Job Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Create Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock client for model customization\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "print(\"üîß Setting up Bedrock fine-tuning job...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure fine-tuning job parameters\n",
    "datetime_string = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Job configuration\n",
    "customizationType = \"FINE_TUNING\"\n",
    "customModelName = \"custom-titan-lite-model\"\n",
    "baseModelIdentifier = \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\"\n",
    "roleArn = f\"arn:aws:iam::{account_id}:role/Bedrock-Finetuning-Role-{account_id}\"\n",
    "jobName = f\"Titan-Lite-Finetune-Job-{datetime_string}\"\n",
    "\n",
    "# Hyperparameters for training\n",
    "hyperParameters = {\n",
    "    \"epochCount\": \"1\",                    # Number of training epochs\n",
    "    \"batchSize\": \"1\",                    # Batch size for training\n",
    "    \"learningRate\": \".0001\",              # Learning rate\n",
    "    \"learningRateWarmupSteps\": \"0\"       # Warmup steps\n",
    "}\n",
    "\n",
    "print(f\"üìã Job Name: {jobName}\")\n",
    "print(f\"üéØ Base Model: Amazon Titan Text Lite v1\")\n",
    "print(f\"‚öôÔ∏è Hyperparameters: {hyperParameters}\")\n",
    "\n",
    "# Create the fine-tuning job\n",
    "print(\"üöÄ Starting fine-tuning job...\")\n",
    "response_ft = bedrock.create_model_customization_job(\n",
    "    jobName=jobName,\n",
    "    customModelName=customModelName,\n",
    "    customizationType=customizationType,\n",
    "    roleArn=roleArn,\n",
    "    baseModelIdentifier=baseModelIdentifier,\n",
    "    hyperParameters=hyperParameters,\n",
    "    # Training data location\n",
    "    trainingDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/train.jsonl\"},\n",
    "    # Validation data location\n",
    "    validationDataConfig={'validators': [{\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/validation.jsonl\"}]},\n",
    "    # Output location for trained model\n",
    "    outputDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/finetuning-output\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the job ARN for tracking\n",
    "jobArn = response_ft.get('jobArn')\n",
    "print(f\"‚úÖ Fine-tuning job created successfully!\")\n",
    "print(f\"üìç Job ARN: {jobArn}\")\n",
    "print(f\"‚è±Ô∏è Training will take several hours to complete...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Training Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current status of the fine-tuning job\n",
    "print(f\"üîç Checking status for job: {jobName}\")\n",
    "\n",
    "job_details = bedrock.get_model_customization_job(jobIdentifier=jobName)\n",
    "status = job_details[\"status\"]\n",
    "\n",
    "print(f\"üìä Current Status: {status}\")\n",
    "\n",
    "# Display additional job information\n",
    "if 'creationTime' in job_details:\n",
    "    print(f\"üïê Started: {job_details['creationTime']}\")\n",
    "if 'endTime' in job_details:\n",
    "    print(f\"üèÅ Completed: {job_details['endTime']}\")\n",
    "\n",
    "# Status-specific messages\n",
    "if status == 'InProgress':\n",
    "    print(\"‚è≥ Training is in progress. Please wait and check again later.\")\n",
    "elif status == 'Completed':\n",
    "    print(\"‚úÖ Training completed successfully! Ready for provisioned throughput.\")\n",
    "elif status == 'Failed':\n",
    "    print(\"‚ùå Training failed. Check the job details for error information.\")\n",
    "    if 'failureMessage' in job_details:\n",
    "        print(f\"Error: {job_details['failureMessage']}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provisioned Throughput Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Provisioned Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchase provisioned throughput for the custom model\n",
    "print(\"üí∞ Setting up provisioned throughput...\")\n",
    "\n",
    "# ‚ö†Ô∏è WARNING: This will incur hourly charges!\n",
    "print(\"‚ö†Ô∏è  WARNING: Provisioned throughput incurs hourly charges!\")\n",
    "print(\"üí° Remember to delete the provisioned throughput when done testing.\")\n",
    "\n",
    "response_pt = bedrock.create_provisioned_model_throughput(\n",
    "    modelId=customModelName,                           # Our custom model\n",
    "    provisionedModelName=\"ProvisionedCustomTitanLite\", # Name for the provisioned instance\n",
    "    modelUnits=1                                       # Minimum 1 unit required\n",
    ")\n",
    "\n",
    "provisionedModelArn = response_pt.get('provisionedModelArn')\n",
    "\n",
    "print(f\"‚úÖ Provisioned throughput created!\")\n",
    "print(f\"üìç Provisioned Model ARN: {provisionedModelArn}\")\n",
    "print(f\"‚è±Ô∏è Provisioning may take a few minutes to become active...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model with a sample dialogue\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "# Example test prompt (replace with your own dialogue)\n",
    "test_dialogue = \"\"\"\n",
    "Person A: Hi, I'm calling about my credit card bill. I noticed some charges I don't recognize.\n",
    "Person B: I'd be happy to help you with that. Can you provide me with your account number?\n",
    "Person A: Sure, it's 1234-5678-9012-3456.\n",
    "Person B: Thank you. I can see the charges you're referring to. Let me investigate these for you.\n",
    "\"\"\"\n",
    "\n",
    "# Format the prompt using the same template as training\n",
    "prompt = f\"Identify the key topic representing the dialogue. \\n\\nDialogue: {test_dialogue}\"\n",
    "\n",
    "print(f\"üß™ Testing with prompt:\")\n",
    "print(f\"{prompt}\\n\")\n",
    "\n",
    "# Configure inference parameters\n",
    "body = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.5,    # Controls randomness (0.0 = deterministic, 1.0 = very random)\n",
    "    \"p\": 0.9,             # Top-p sampling (nucleus sampling)\n",
    "    \"max_tokens\": 512,    # Maximum tokens to generate\n",
    "}\n",
    "\n",
    "print(\"üöÄ Invoking fine-tuned model...\")\n",
    "\n",
    "# Call the fine-tuned model\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=provisionedModelArn,  # Use our provisioned custom model\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "response_body = json.loads(response['body'].read())\n",
    "generated_text = response_body.get('outputText', '')\n",
    "\n",
    "print(f\"üéØ Model Response:\")\n",
    "print(f\"{generated_text}\")\n",
    "\n",
    "print(\"‚úÖ Fine-tuned model test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Important!)\n",
    "\n",
    "**‚ö†Ô∏è Don't forget to clean up resources to avoid ongoing charges:**\n",
    "\n",
    "1. **Delete Provisioned Throughput** (incurs hourly charges)\n",
    "2. **Delete Custom Model** (if no longer needed)\n",
    "3. **Delete S3 Bucket** (if no longer needed)\n",
    "4. **Delete IAM Role and Policy** (if no longer needed)\n",
    "\n",
    "```python\n",
    "# Delete provisioned throughput\n",
    "bedrock.delete_provisioned_model_throughput(\n",
    "    provisionedModelId='ProvisionedCustomTitanLite'\n",
    ")\n",
    "\n",
    "# Delete custom model\n",
    "bedrock.delete_custom_model(modelIdentifier=customModelName)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the complete workflow for fine-tuning a foundation model on Amazon Bedrock. This process enables you to create specialized AI models for specific tasks while leveraging the capabilities of pre-trained foundation models.\n",
    "\n",
    "Key accomplishments:\n",
    "1. **Infrastructure Setup**: We created the necessary AWS resources including an S3 bucket for data storage and IAM roles with appropriate permissions.\n",
    "\n",
    "2. **Dataset Preparation**: We processed the DialogSum dataset to extract dialogue-topic pairs, formatted them for fine-tuning, and uploaded them to S3.\n",
    "\n",
    "3. **Model Fine-tuning**: We configured and launched a fine-tuning job on Amazon Titan Text Lite, specifying appropriate hyperparameters for our task.\n",
    "\n",
    "4. **Deployment**: We set up provisioned throughput to make our custom model available for inference.\n",
    "\n",
    "5. **Testing**: We demonstrated how to use the fine-tuned model to identify topics from dialogue samples.\n",
    "\n",
    "This fine-tuning approach has several advantages:\n",
    "- **Task Specialization**: The model is optimized specifically for dialogue topic identification\n",
    "- **Improved Performance**: Fine-tuned models typically outperform base models on specific tasks\n",
    "- **Consistent Output Format**: Responses follow the training patterns, providing more predictable outputs\n",
    "- **API Compatibility**: Uses the same API as foundation models, making integration seamless\n",
    "\n",
    "Important considerations:\n",
    "- **Cost Management**: Remember to delete provisioned throughput when not in use to avoid ongoing charges\n",
    "- **Training Time**: Fine-tuning jobs can take several hours depending on dataset size and model complexity\n",
    "- **Dataset Quality**: The quality and representativeness of your training data significantly impacts model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
